[
  {
    "question": "What SQLAlchemy do in SQLDatabaseChain?",
    "contexts": [
      "# SQL Database Chain This example demonstrates the use of the `SQLDatabaseChain` for answering questions over a SQL database. Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The `SQLDatabaseChain` can therefore be used with any SQL dialect supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, [Databricks](/docs/ecosystem/integrations/databricks.html) and SQLite. Please refer to the SQLAlchemy documentation for more information about requirements for connecting to your database. For example, a connection to MySQL requires an appropriate connector such as PyMySQL. A URI for a MySQL connection might look like: `mysql+pymysql://user:pass@some_mysql_db_address/db_name`. This demonstration uses SQLite and the example Chinook database. To set it up, follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the `.db` file in a notebooks folder at the root of this repository. ```python from langchain_openai import OpenAI from langchain_community.utilities import SQLDatabase from langchain_experimental.sql import SQLDatabaseChain ``` ```python db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\") llm = OpenAI(temperature=0, verbose=True) ``` **NOTE:** For data-sensitive projects, you can specify `return_direct=True` in the `SQLDatabaseChain` initialization to directly return the output of the SQL query without any additional formatting. This prevents the LLM from seeing any contents within the database. Note, however, the LLM still has access to the database scheme (i.e. dialect, table and key names) by default. ```python db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True) ``` ```python db_chain.run(\"How many employees are there?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many employees are there? SQLQuery: /workspace/langchain/langchain/sql_database.py:191: SAWarning: Dialect sqlite+pysqlite does *not* support Decimal objects natively, and SQLAlchemy must convert from floating point - rounding errors and other issues may occur. Please consider storing Decimal numbers as strings or integers on this platform for lossless storage. sample_rows = connection.execute(command) SELECT COUNT(*) FROM \"Employee\"; SQLResult: [(8,)] Answer:There are 8 employees. > Finished chain. 'There are 8 employees.' ``` </CodeOutputBlock> ## Use Query Checker Sometimes the Language Model generates invalid SQL with small mistakes that can be self-corrected using the same technique used by the SQL Database Agent to try and fix the SQL using the LLM. You can simply specify this option when creating the chain: ```python db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, use_query_checker=True) ``` ```python db_chain.run(\"How many albums by Aerosmith?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many albums by Aerosmith? SQLQuery:SELECT COUNT(*) FROM Album WHERE ArtistId = 3; SQLResult: [(1,)] Answer:There is 1 album by Aerosmith. > Finished chain. 'There is 1 album by Aerosmith.' ``` </CodeOutputBlock> ## Customize Prompt You can also customize the prompt that is used. Here is an example prompting it to understand that foobar is the same as the Employee table ```python from langchain.prompts.prompt import PromptTemplate _DEFAULT_TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Use the following format: Question: \"Question here\" SQLQuery: \"SQL Query to run\" SQLResult: \"Result of the SQLQuery\" Answer: \"Final answer here\" Only use the following tables: {table_info} If someone asks for the table foobar, they really mean the employee table. Question: {input}\"\"\" PROMPT = PromptTemplate( input_variables=[\"input\", \"table_info\", \"dialect\"], template=_DEFAULT_TEMPLATE ) ``` ```python db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True) ``` ```python db_chain.run(\"How many employees are there in the foobar table?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many employees are there in the foobar table? SQLQuery:SELECT COUNT(*) FROM Employee; SQLResult: [(8,)] Answer:There are 8 employees in the foobar table. > Finished chain. 'There are 8 employees in the foobar table.' ``` </CodeOutputBlock> ##"
    ],
    "ground_truth": "SQLAlchemy is used to connect to SQL databases in the SQLDatabaseChain.",
    "synthesizer_name": "single_hop_specifc_query_synthesizer"
  },
  {
    "question": "What is the structure of the Invoice table in the database?",
    "contexts": [
      "Return Intermediate Steps You can also return the intermediate steps of the SQLDatabaseChain. This allows you to access the SQL statement that was generated, as well as the result of running that against the SQL Database. ```python db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True, use_query_checker=True, return_intermediate_steps=True) ``` ```python result = db_chain(\"How many employees are there in the foobar table?\") result[\"intermediate_steps\"] ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many employees are there in the foobar table? SQLQuery:SELECT COUNT(*) FROM Employee; SQLResult: [(8,)] Answer:There are 8 employees in the foobar table. > Finished chain. [{'input': 'How many employees are there in the foobar table?\\nSQLQuery:SELECT COUNT(*) FROM Employee;\\nSQLResult: [(8,)]\\nAnswer:', 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE \"Artist\" (\\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Artist table:\\nArtistId\\tName\\n1\\tAC/DC\\n2\\tAccept\\n3\\tAerosmith\\n*/\\n\\n\\nCREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/\\n\\n\\nCREATE TABLE \"Genre\" (\\n\\t\"GenreId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"GenreId\")\\n)\\n\\n/*\\n3 rows from Genre table:\\nGenreId\\tName\\n1\\tRock\\n2\\tJazz\\n3\\tMetal\\n*/\\n\\n\\nCREATE TABLE \"MediaType\" (\\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"MediaTypeId\")\\n)\\n\\n/*\\n3 rows from MediaType table:\\nMediaTypeId\\tName\\n1\\tMPEG audio file\\n2\\tProtected AAC audio file\\n3\\tProtected MPEG-4 video file\\n*/\\n\\n\\nCREATE TABLE \"Playlist\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from Playlist table:\\nPlaylistId\\tName\\n1\\tMusic\\n2\\tMovies\\n3\\tTV Shows\\n*/\\n\\n\\nCREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLuís\\tGonçalves\\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tSão José dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tKöhler\\tNone\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFrançois\\tTremblay\\tNone\\t1498 rue Bélanger\\tMontréal\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"Track\" (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL, \\n\\t\"AlbumId\" INTEGER, \\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"GenreId\" INTEGER, \\n\\t\"Composer\" NVARCHAR(220), \\n\\t\"Milliseconds\" INTEGER NOT NULL, \\n\\t\"Bytes\" INTEGER, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"TrackId\"), \\n\\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \\n\\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \\n\\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\\n)\\n\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tAlbumId\\tMediaTypeId\\tGenreId\\tComposer\\tMilliseconds\\tBytes\\tUnitPrice\\n1\\tFor Those About To Rock (We Salute You)\\t1\\t1\\t1\\tAngus Young, Malcolm Young, Brian Johnson\\t343719\\t11170334\\t0.99\\n2\\tBalls to the Wall\\t2\\t2\\t1\\tNone\\t342562\\t5510424\\t0.99\\n3\\tFast As a Shark\\t3\\t2\\t1\\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\\t230619\\t3990994\\t0.99\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/\\n\\n\\nCREATE TABLE \"PlaylistTrack\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"PlaylistId\", \"TrackId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"PlaylistId\") REFERENCES \"Playlist\" (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from PlaylistTrack table:\\nPlaylistId\\tTrackId\\n1\\t3402\\n1\\t3389\\n1\\t3390\\n*/', 'stop': ['\\nSQLResult:']}, 'SELECT COUNT(*) FROM Employee;', {'query': 'SELECT COUNT(*) FROM Employee;', 'dialect': 'sqlite'}, 'SELECT COUNT(*) FROM Employee;', '[(8,)]'] ``` </CodeOutputBlock> ##"
    ],
    "ground_truth": "The Invoice table is structured with the following columns: InvoiceId (INTEGER NOT NULL, PRIMARY KEY), CustomerId (INTEGER NOT NULL, FOREIGN KEY referencing Customer), InvoiceDate (DATETIME NOT NULL), BillingAddress (NVARCHAR(70)), BillingCity (NVARCHAR(40)), BillingState (NVARCHAR(40)), BillingCountry (NVARCHAR(40)), BillingPostalCode (NVARCHAR(10)), and Total (NUMERIC(10, 2) NOT NULL).",
    "synthesizer_name": "single_hop_specifc_query_synthesizer"
  },
  {
    "question": "Wht are the code update recomendations for LangChain v0.3 and what breaking changes should I be aware of?",
    "contexts": [
      "<1-hop>\n\n# LangChain v0.3 *Last updated: 09.16.24* ## What's changed * All packages have been upgraded from Pydantic 1 to Pydantic 2 internally. Use of Pydantic 2 in user code is fully supported with all packages without the need for bridges like `langchain_core.pydantic_v1` or `pydantic.v1`. * Pydantic 1 will no longer be supported as it reached its end-of-life in June 2024. * Python 3.8 will no longer be supported as its end-of-life is October 2024. **These are the only breaking changes.** ## What’s new The following features have been added during the development of 0.2.x: - Moved more integrations from `langchain-community` to their own `langchain-x` packages. This is a non-breaking change, as the legacy implementations are left in `langchain-community` and marked as deprecated. This allows us to better manage the dependencies of, test, and version these integrations. You can see all the latest integration packages in the [API reference](https://python.langchain.com/v0.2/api_reference/reference.html#integrations). - Simplified tool definition and usage. Read more [here](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/). - Added utilities for interacting with chat models: [universal model constructor](https://python.langchain.com/v0.2/docs/how_to/chat_models_universal_init/), [rate limiter](https://python.langchain.com/v0.2/docs/how_to/chat_model_rate_limiting/), [message utilities](https://python.langchain.com/v0.2/docs/how_to/#messages), - Added the ability to [dispatch custom events](https://python.langchain.com/v0.2/docs/how_to/callbacks_custom_events/). - Revamped integration docs and API reference. Read more [here](https://blog.langchain.dev/langchain-integration-docs-revamped/). - Marked as deprecated a number of legacy chains and added migration guides for all of them. These are slated for removal in `langchain` 1.0.0. See the deprecated chains and associated [migration guides here](https://python.langchain.com/v0.2/docs/versions/migrating_chains/). ##",
      "<2-hop>\n\nHow to update your code If you're using `langchain` / `langchain-community` / `langchain-core` 0.0 or 0.1, we recommend that you first [upgrade to 0.2](https://python.langchain.com/v0.2/docs/versions/v0_2/). If you're using `langgraph`, upgrade to `langgraph>=0.2.20,<0.3`. This will work with either 0.2 or 0.3 versions of all the base packages. Here is a complete list of all packages that have been released and what we recommend upgrading your version constraints to. Any package that now requires `langchain-core` 0.3 had a minor version bump. Any package that is now compatible with both `langchain-core` 0.2 and 0.3 had a patch version bump. You can use the `langchain-cli` to update deprecated imports automatically. The CLI will handle updating deprecated imports that were introduced in LangChain 0.0.x and LangChain 0.1, as well as updating the `langchain_core.pydantic_v1` and `langchain.pydantic_v1` imports. ### Base packages | Package | Latest | Recommended constraint | |--------------------------|--------|------------------------| | langchain | 0.3.0 | >=0.3,&lt;0.4 | | langchain-community | 0.3.0 | >=0.3,&lt;0.4 | | langchain-text-splitters | 0.3.0 | >=0.3,&lt;0.4 | | langchain-core | 0.3.0 | >=0.3,&lt;0.4 | | langchain-experimental | 0.3.0 | >=0.3,&lt;0.4 | ### Downstream packages | Package | Latest | Recommended constraint | |-----------|--------|------------------------| | langgraph | 0.2.20 | >=0.2.20,&lt;0.3 | | langserve | 0.3.0 | >=0.3,&lt;0.4 | ### Integration packages | Package | Latest | Recommended constraint | | -------------------------------------- | ------- | -------------------------- | | langchain-ai21 | 0.2.0 | >=0.2,&lt;0.3 | | langchain-aws | 0.2.0 | >=0.2,&lt;0.3 | | langchain-anthropic | 0.2.0 | >=0.2,&lt;0.3 | | langchain-astradb | 0.4.1 | >=0.4.1,&lt;0.5 | | langchain-azure-dynamic-sessions | 0.2.0 | >=0.2,&lt;0.3 | | langchain-box | 0.2.0 | >=0.2,&lt;0.3 | | langchain-chroma | 0.1.4 | >=0.1.4,&lt;0.2 | | langchain-cohere | 0.3.0 | >=0.3,&lt;0.4 | | langchain-elasticsearch | 0.3.0 | >=0.3,&lt;0.4 | | langchain-exa | 0.2.0 | >=0.2,&lt;0.3 | | langchain-fireworks | 0.2.0 | >=0.2,&lt;0.3 | | langchain-groq | 0.2.0 | >=0.2,&lt;0.3 | | langchain-google-community | 2.0.0 | >=2,&lt;3 | | langchain-google-genai | 2.0.0 | >=2,&lt;3 | | langchain-google-vertexai | 2.0.0 | >=2,&lt;3 | | langchain-huggingface | 0.1.0 | >=0.1,&lt;0.2 | | langchain-ibm | 0.3.0 | >=0.3,&lt;0.4 | | langchain-milvus | 0.1.6 | >=0.1.6,&lt;0.2 | | langchain-mistralai | 0.2.0 | >=0.2,&lt;0.3 | | langchain-mongodb | 0.2.0 | >=0.2,&lt;0.3 | | langchain-nomic | 0.1.3 | >=0.1.3,&lt;0.2 | | langchain-nvidia | 0.3.0 | >=0.3,&lt;0.4 | | langchain-ollama | 0.2.0 | >=0.2,&lt;0.3 | | langchain-openai | 0.2.0 | >=0.2,&lt;0.3 | | langchain-pinecone | 0.2.0 | >=0.2,&lt;0.3 | | langchain-postgres | 0.0.13 | >=0.0.13,&lt;0.1 | | langchain-prompty | 0.1.0 | >=0.1,&lt;0.2 | | langchain-qdrant | 0.1.4 | >=0.1.4,&lt;0.2 | | langchain-redis | 0.1.0 | >=0.1,&lt;0.2 | | langchain-sema4 | 0.2.0 | >=0.2,&lt;0.3 | | langchain-together | 0.2.0 | >=0.2,&lt;0.3 | | langchain-unstructured | 0.1.4 | >=0.1.4,&lt;0.2 | | langchain-upstage | 0.3.0 | >=0.3,&lt;0.4 | | langchain-voyageai | 0.2.0 | >=0.2,&lt;0.3 | | langchain-weaviate | 0.0.3 | >=0.0.3,&lt;0.1 | Once you've updated to recent versions of the packages, you may need to address the following issues stemming from the internal switch from Pydantic v1 to Pydantic v2: - If your code depends on Pydantic aside from LangChain, you will need to upgrade your pydantic version constraints to be `pydantic>=2,<3`. See [Pydantic’s migration guide](https://docs.pydantic.dev/latest/migration/) for help migrating your non-LangChain code to Pydantic v2 if you use pydantic v1. - There are a number of side effects to LangChain components caused by the internal switch from Pydantic v1 to v2. We have listed some of the common cases below together with the recommended solutions. ##"
    ],
    "ground_truth": "For LangChain v0.3, the code update recommendations include upgrading from any version of `langchain` / `langchain-community` / `langchain-core` 0.0 or 0.1 to 0.2 first. If using `langgraph`, upgrade to `langgraph>=0.2.20,<0.3`. The breaking changes to be aware of are that all packages have been upgraded from Pydantic 1 to Pydantic 2, and Pydantic 1 will no longer be supported after June 2024. Additionally, Python 3.8 will no longer be supported after October 2024.",
    "synthesizer_name": "multi_hop_abstract_query_synthesizer"
  },
  {
    "question": "How can the SQLDatabaseChain be utilized for async operations while ensuring effective handling of SQL queries and responses?",
    "contexts": [
      "<1-hop>\n\n# SQL Database Chain This example demonstrates the use of the `SQLDatabaseChain` for answering questions over a SQL database. Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The `SQLDatabaseChain` can therefore be used with any SQL dialect supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, [Databricks](/docs/ecosystem/integrations/databricks.html) and SQLite. Please refer to the SQLAlchemy documentation for more information about requirements for connecting to your database. For example, a connection to MySQL requires an appropriate connector such as PyMySQL. A URI for a MySQL connection might look like: `mysql+pymysql://user:pass@some_mysql_db_address/db_name`. This demonstration uses SQLite and the example Chinook database. To set it up, follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the `.db` file in a notebooks folder at the root of this repository. ```python from langchain_openai import OpenAI from langchain_community.utilities import SQLDatabase from langchain_experimental.sql import SQLDatabaseChain ``` ```python db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\") llm = OpenAI(temperature=0, verbose=True) ``` **NOTE:** For data-sensitive projects, you can specify `return_direct=True` in the `SQLDatabaseChain` initialization to directly return the output of the SQL query without any additional formatting. This prevents the LLM from seeing any contents within the database. Note, however, the LLM still has access to the database scheme (i.e. dialect, table and key names) by default. ```python db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True) ``` ```python db_chain.run(\"How many employees are there?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many employees are there? SQLQuery: /workspace/langchain/langchain/sql_database.py:191: SAWarning: Dialect sqlite+pysqlite does *not* support Decimal objects natively, and SQLAlchemy must convert from floating point - rounding errors and other issues may occur. Please consider storing Decimal numbers as strings or integers on this platform for lossless storage. sample_rows = connection.execute(command) SELECT COUNT(*) FROM \"Employee\"; SQLResult: [(8,)] Answer:There are 8 employees. > Finished chain. 'There are 8 employees.' ``` </CodeOutputBlock> ## Use Query Checker Sometimes the Language Model generates invalid SQL with small mistakes that can be self-corrected using the same technique used by the SQL Database Agent to try and fix the SQL using the LLM. You can simply specify this option when creating the chain: ```python db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, use_query_checker=True) ``` ```python db_chain.run(\"How many albums by Aerosmith?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many albums by Aerosmith? SQLQuery:SELECT COUNT(*) FROM Album WHERE ArtistId = 3; SQLResult: [(1,)] Answer:There is 1 album by Aerosmith. > Finished chain. 'There is 1 album by Aerosmith.' ``` </CodeOutputBlock> ## Customize Prompt You can also customize the prompt that is used. Here is an example prompting it to understand that foobar is the same as the Employee table ```python from langchain.prompts.prompt import PromptTemplate _DEFAULT_TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Use the following format: Question: \"Question here\" SQLQuery: \"SQL Query to run\" SQLResult: \"Result of the SQLQuery\" Answer: \"Final answer here\" Only use the following tables: {table_info} If someone asks for the table foobar, they really mean the employee table. Question: {input}\"\"\" PROMPT = PromptTemplate( input_variables=[\"input\", \"table_info\", \"dialect\"], template=_DEFAULT_TEMPLATE ) ``` ```python db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True) ``` ```python db_chain.run(\"How many employees are there in the foobar table?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many employees are there in the foobar table? SQLQuery:SELECT COUNT(*) FROM Employee; SQLResult: [(8,)] Answer:There are 8 employees in the foobar table. > Finished chain. 'There are 8 employees in the foobar table.' ``` </CodeOutputBlock> ##",
      "<2-hop>\n\nReturn Intermediate Steps You can also return the intermediate steps of the SQLDatabaseChain. This allows you to access the SQL statement that was generated, as well as the result of running that against the SQL Database. ```python db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True, use_query_checker=True, return_intermediate_steps=True) ``` ```python result = db_chain(\"How many employees are there in the foobar table?\") result[\"intermediate_steps\"] ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many employees are there in the foobar table? SQLQuery:SELECT COUNT(*) FROM Employee; SQLResult: [(8,)] Answer:There are 8 employees in the foobar table. > Finished chain. [{'input': 'How many employees are there in the foobar table?\\nSQLQuery:SELECT COUNT(*) FROM Employee;\\nSQLResult: [(8,)]\\nAnswer:', 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE \"Artist\" (\\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Artist table:\\nArtistId\\tName\\n1\\tAC/DC\\n2\\tAccept\\n3\\tAerosmith\\n*/\\n\\n\\nCREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/\\n\\n\\nCREATE TABLE \"Genre\" (\\n\\t\"GenreId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"GenreId\")\\n)\\n\\n/*\\n3 rows from Genre table:\\nGenreId\\tName\\n1\\tRock\\n2\\tJazz\\n3\\tMetal\\n*/\\n\\n\\nCREATE TABLE \"MediaType\" (\\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"MediaTypeId\")\\n)\\n\\n/*\\n3 rows from MediaType table:\\nMediaTypeId\\tName\\n1\\tMPEG audio file\\n2\\tProtected AAC audio file\\n3\\tProtected MPEG-4 video file\\n*/\\n\\n\\nCREATE TABLE \"Playlist\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from Playlist table:\\nPlaylistId\\tName\\n1\\tMusic\\n2\\tMovies\\n3\\tTV Shows\\n*/\\n\\n\\nCREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLuís\\tGonçalves\\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tSão José dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tKöhler\\tNone\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFrançois\\tTremblay\\tNone\\t1498 rue Bélanger\\tMontréal\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"Track\" (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL, \\n\\t\"AlbumId\" INTEGER, \\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"GenreId\" INTEGER, \\n\\t\"Composer\" NVARCHAR(220), \\n\\t\"Milliseconds\" INTEGER NOT NULL, \\n\\t\"Bytes\" INTEGER, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"TrackId\"), \\n\\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \\n\\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \\n\\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\\n)\\n\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tAlbumId\\tMediaTypeId\\tGenreId\\tComposer\\tMilliseconds\\tBytes\\tUnitPrice\\n1\\tFor Those About To Rock (We Salute You)\\t1\\t1\\t1\\tAngus Young, Malcolm Young, Brian Johnson\\t343719\\t11170334\\t0.99\\n2\\tBalls to the Wall\\t2\\t2\\t1\\tNone\\t342562\\t5510424\\t0.99\\n3\\tFast As a Shark\\t3\\t2\\t1\\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\\t230619\\t3990994\\t0.99\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/\\n\\n\\nCREATE TABLE \"PlaylistTrack\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"PlaylistId\", \"TrackId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"PlaylistId\") REFERENCES \"Playlist\" (\"PlaylistId\")\\n)\\n\\n/*\\n3 rows from PlaylistTrack table:\\nPlaylistId\\tTrackId\\n1\\t3402\\n1\\t3389\\n1\\t3390\\n*/', 'stop': ['\\nSQLResult:']}, 'SELECT COUNT(*) FROM Employee;', {'query': 'SELECT COUNT(*) FROM Employee;', 'dialect': 'sqlite'}, 'SELECT COUNT(*) FROM Employee;', '[(8,)]'] ``` </CodeOutputBlock> ##",
      "<3-hop>\n\nChoosing how to limit the number of rows returned If you are querying for several rows of a table you can select the maximum number of results you want to get by using the 'top_k' parameter (default is 10). This is useful for avoiding query results that exceed the prompt max length or consume tokens unnecessarily. ```python db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, use_query_checker=True, top_k=3) ``` ```python db_chain.run(\"What are some example tracks by composer Johann Sebastian Bach?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... What are some example tracks by composer Johann Sebastian Bach? SQLQuery:SELECT Name FROM Track WHERE Composer = 'Johann Sebastian Bach' LIMIT 3 SQLResult: [('Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace',), ('Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria',), ('Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude',)] Answer:Examples of tracks by Johann Sebastian Bach are Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace, Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria, and Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude. > Finished chain. 'Examples of tracks by Johann Sebastian Bach are Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace, Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria, and Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude.' ``` </CodeOutputBlock> ## Adding example rows from each table Sometimes, the format of the data is not obvious and it is optimal to include a sample of rows from the tables in the prompt to allow the LLM to understand the data before providing a final query. Here we will use this feature to let the LLM know that artists are saved with their full names by providing two rows from the `Track` table. ```python db = SQLDatabase.from_uri( \"sqlite:///../../../../notebooks/Chinook.db\", include_tables=['Track'], # we include only one table to save tokens in the prompt :) sample_rows_in_table_info=2) ``` The sample rows are added to the prompt after each corresponding table's column information: ```python print(db.table_info) ``` <CodeOutputBlock lang=\"python\"> ``` CREATE TABLE \"Track\" ( \"TrackId\" INTEGER NOT NULL, \"Name\" NVARCHAR(200) NOT NULL, \"AlbumId\" INTEGER, \"MediaTypeId\" INTEGER NOT NULL, \"GenreId\" INTEGER, \"Composer\" NVARCHAR(220), \"Milliseconds\" INTEGER NOT NULL, \"Bytes\" INTEGER, \"UnitPrice\" NUMERIC(10, 2) NOT NULL, PRIMARY KEY (\"TrackId\"), FOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), FOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), FOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\") ) /* 2 rows from Track table: TrackId Name AlbumId MediaTypeId GenreId Composer Milliseconds Bytes UnitPrice 1 For Those About To Rock (We Salute You) 1 1 1 Angus Young, Malcolm Young, Brian Johnson 343719 11170334 0.99 2 Balls to the Wall 2 2 1 None 342562 5510424 0.99 */ ``` </CodeOutputBlock> ```python db_chain = SQLDatabaseChain.from_llm(llm, db, use_query_checker=True, verbose=True) ``` ```python db_chain.run(\"What are some example tracks by Bach?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... What are some example tracks by Bach? SQLQuery:SELECT \"Name\", \"Composer\" FROM \"Track\" WHERE \"Composer\" LIKE '%Bach%' LIMIT 5 SQLResult: [('American Woman', 'B. Cummings/G. Peterson/M.J. Kale/R. Bachman'), ('Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace', 'Johann Sebastian Bach'), ('Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria', 'Johann Sebastian Bach'), ('Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude', 'Johann Sebastian Bach'), ('Toccata and Fugue in D Minor, BWV 565: I. Toccata', 'Johann Sebastian Bach')] Answer:Tracks by Bach include 'American Woman', 'Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace', 'Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria', 'Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude', and 'Toccata and Fugue in D Minor, BWV 565: I. Toccata'. > Finished chain. 'Tracks by Bach include \\'American Woman\\', \\'Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\\', \\'Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria\\', \\'Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude\\', and \\'Toccata and Fugue in D Minor, BWV 565: I. Toccata\\'.' ``` </CodeOutputBlock> ### Custom Table Info In some cases, it can be useful to provide custom table information instead of using the automatically generated table definitions and the first `sample_rows_in_table_info` sample rows. For example, if you know that the first few rows of a table are uninformative, it could help to manually provide example rows that are more diverse or provide more information to the model. It is also possible to limit the columns that will be visible to the model if there are unnecessary columns. This information can be provided as a dictionary with table names as the keys and table information as the values. For example, let's provide a custom definition and sample rows for the Track table with only a few columns: ```python custom_table_info = { \"Track\": \"\"\"CREATE TABLE Track ( \"TrackId\" INTEGER NOT NULL, \"Name\" NVARCHAR(200) NOT NULL, \"Composer\" NVARCHAR(220), PRIMARY KEY (\"TrackId\") ) /* 3 rows from Track table: TrackId Name Composer 1 For Those About To Rock (We Salute You) Angus Young, Malcolm Young, Brian Johnson 2 Balls to the Wall None 3 My favorite song ever The coolest composer of all time */\"\"\" } ``` ```python db = SQLDatabase.from_uri( \"sqlite:///../../../../notebooks/Chinook.db\", include_tables=['Track', 'Playlist'], sample_rows_in_table_info=2, custom_table_info=custom_table_info) print(db.table_info) ``` <CodeOutputBlock lang=\"python\"> ``` CREATE TABLE \"Playlist\" ( \"PlaylistId\" INTEGER NOT NULL, \"Name\" NVARCHAR(120), PRIMARY KEY (\"PlaylistId\") ) /* 2 rows from Playlist table: PlaylistId Name 1 Music 2 Movies */ CREATE TABLE Track ( \"TrackId\" INTEGER NOT NULL, \"Name\" NVARCHAR(200) NOT NULL, \"Composer\" NVARCHAR(220), PRIMARY KEY (\"TrackId\") ) /* 3 rows from Track table: TrackId Name Composer 1 For Those About To Rock (We Salute You) Angus Young, Malcolm Young, Brian Johnson 2 Balls to the Wall None 3 My favorite song ever The coolest composer of all time */ ``` </CodeOutputBlock> Note how our custom table definition and sample rows for `Track` overrides the `sample_rows_in_table_info` parameter. Tables that are not overridden by `custom_table_info`, in this example `Playlist`, will have their table info gathered automatically as usual. ```python db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True) db_chain.run(\"What are some example tracks by Bach?\") ``` <CodeOutputBlock",
      "<4-hop>\n\nlang=\"python\"> ``` > Entering new SQLDatabaseChain chain... What are some example tracks by Bach? SQLQuery:SELECT \"Name\" FROM Track WHERE \"Composer\" LIKE '%Bach%' LIMIT 5; SQLResult: [('American Woman',), ('Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace',), ('Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria',), ('Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude',), ('Toccata and Fugue in D Minor, BWV 565: I. Toccata',)] Answer:text='You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n\\nUse the following format:\\n\\nQuestion: \"Question here\"\\nSQLQuery: \"SQL Query to run\"\\nSQLResult: \"Result of the SQLQuery\"\\nAnswer: \"Final answer here\"\\n\\nOnly use the following tables:\\n\\nCREATE TABLE \"Playlist\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"PlaylistId\")\\n)\\n\\n/*\\n2 rows from Playlist table:\\nPlaylistId\\tName\\n1\\tMusic\\n2\\tMovies\\n*/\\n\\nCREATE TABLE Track (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL,\\n\\t\"Composer\" NVARCHAR(220),\\n\\tPRIMARY KEY (\"TrackId\")\\n)\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tComposer\\n1\\tFor Those About To Rock (We Salute You)\\tAngus Young, Malcolm Young, Brian Johnson\\n2\\tBalls to the Wall\\tNone\\n3\\tMy favorite song ever\\tThe coolest composer of all time\\n*/\\n\\nQuestion: What are some example tracks by Bach?\\nSQLQuery:SELECT \"Name\" FROM Track WHERE \"Composer\" LIKE \\'%Bach%\\' LIMIT 5;\\nSQLResult: [(\\'American Woman\\',), (\\'Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\\',), (\\'Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria\\',), (\\'Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude\\',), (\\'Toccata and Fugue in D Minor, BWV 565: I. Toccata\\',)]\\nAnswer:' You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question. Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database. Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers. Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table. Use the following format: Question: \"Question here\" SQLQuery: \"SQL Query to run\" SQLResult: \"Result of the SQLQuery\" Answer: \"Final answer here\" Only use the following tables: CREATE TABLE \"Playlist\" ( \"PlaylistId\" INTEGER NOT NULL, \"Name\" NVARCHAR(120), PRIMARY KEY (\"PlaylistId\") ) /* 2 rows from Playlist table: PlaylistId Name 1 Music 2 Movies */ CREATE TABLE Track ( \"TrackId\" INTEGER NOT NULL, \"Name\" NVARCHAR(200) NOT NULL, \"Composer\" NVARCHAR(220), PRIMARY KEY (\"TrackId\") ) /* 3 rows from Track table: TrackId Name Composer 1 For Those About To Rock (We Salute You) Angus Young, Malcolm Young, Brian Johnson 2 Balls to the Wall None 3 My favorite song ever The coolest composer of all time */ Question: What are some example tracks by Bach? SQLQuery:SELECT \"Name\" FROM Track WHERE \"Composer\" LIKE '%Bach%' LIMIT 5; SQLResult: [('American Woman',), ('Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace',), ('Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria',), ('Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude',), ('Toccata and Fugue in D Minor, BWV 565: I. Toccata',)] Answer: {'input': 'What are some example tracks by Bach?\\nSQLQuery:SELECT \"Name\" FROM Track WHERE \"Composer\" LIKE \\'%Bach%\\' LIMIT 5;\\nSQLResult: [(\\'American Woman\\',), (\\'Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\\',), (\\'Aria Mit 30 Veränderungen, BWV 988 \"Goldberg Variations\": Aria\\',), (\\'Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude\\',), (\\'Toccata and Fugue in D Minor, BWV 565: I. Toccata\\',)]\\nAnswer:', 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE \"Playlist\" (\\n\\t\"PlaylistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"PlaylistId\")\\n)\\n\\n/*\\n2 rows from Playlist table:\\nPlaylistId\\tName\\n1\\tMusic\\n2\\tMovies\\n*/\\n\\nCREATE TABLE Track (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL,\\n\\t\"Composer\" NVARCHAR(220),\\n\\tPRIMARY KEY (\"TrackId\")\\n)\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tComposer\\n1\\tFor Those About To Rock (We Salute You)\\tAngus Young, Malcolm Young, Brian Johnson\\n2\\tBalls to the Wall\\tNone\\n3\\tMy favorite song ever\\tThe coolest composer of all time\\n*/', 'stop': ['\\nSQLResult:']} Examples of tracks by Bach include \"American Woman\", \"Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\", \"Aria Mit 30 Veränderungen, BWV 988 'Goldberg Variations': Aria\", \"Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude\", and \"Toccata and Fugue in D Minor, BWV 565: I. Toccata\". > Finished chain. 'Examples of tracks by Bach include \"American Woman\", \"Concerto for 2 Violins in D Minor, BWV 1043: I. Vivace\", \"Aria Mit 30 Veränderungen, BWV 988 \\'Goldberg Variations\\': Aria\", \"Suite for Solo Cello No. 1 in G Major, BWV 1007: I. Prélude\", and \"Toccata and Fugue in D Minor, BWV 565: I. Toccata\".' ``` </CodeOutputBlock> ### SQL Views In some case, the table schema can be hidden behind a JSON or JSONB column. Adding row samples into the prompt might help won't always describe the data perfectly. For this reason, a custom SQL views can help. ```sql CREATE VIEW accounts_v AS select id, firstname, lastname, email, created_at, updated_at, cast(stats->>'total_post' as int) as total_post, cast(stats->>'total_comments' as int) as total_comments, cast(stats->>'ltv' as int) as ltv FROM accounts; ``` Then limit the tables visible from SQLDatabase to the created view. ```python db = SQLDatabase.from_uri( \"sqlite:///../../../../notebooks/Chinook.db\", include_tables=['accounts_v']) # we include only the",
      "<5-hop>\n\nview ``` ## SQLDatabaseSequentialChain Chain for querying SQL database that is a sequential chain. The chain is as follows: 1. Based on the query, determine which tables to use. 2. Based on those tables, call the normal SQL database chain. This is useful in cases where the number of tables in the database is large. ```python from langchain_experimental.sql import SQLDatabaseSequentialChain db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\") ``` ```python chain = SQLDatabaseSequentialChain.from_llm(llm, db, verbose=True) ``` ```python chain.run(\"How many employees are also customers?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseSequentialChain chain... Table names to use: ['Employee', 'Customer'] > Entering new SQLDatabaseChain chain... How many employees are also customers? SQLQuery:SELECT COUNT(*) FROM Employee e INNER JOIN Customer c ON e.EmployeeId = c.SupportRepId; SQLResult: [(59,)] Answer:59 employees are also customers. > Finished chain. > Finished chain. '59 employees are also customers.' ``` </CodeOutputBlock> ## Using Local Language Models Sometimes you may not have the luxury of using OpenAI or other service-hosted large language model. You can, ofcourse, try to use the `SQLDatabaseChain` with a local model, but will quickly realize that most models you can run locally even with a large GPU struggle to generate the right output. ```python import logging import torch from transformers import AutoTokenizer, GPT2TokenizerFast, pipeline, AutoModelForSeq2SeqLM, AutoModelForCausalLM from langchain_huggingface import HuggingFacePipeline # Note: This model requires a large GPU, e.g. an 80GB A100. See documentation for other ways to run private non-OpenAI models. model_id = \"google/flan-ul2\" model = AutoModelForSeq2SeqLM.from_pretrained(model_id, temperature=0) device_id = -1 # default to no-GPU, but use GPU and half precision mode if available if torch.cuda.is_available(): device_id = 0 try: model = model.half() except RuntimeError as exc: logging.warn(f\"Could not run model in half precision mode: {str(exc)}\") tokenizer = AutoTokenizer.from_pretrained(model_id) pipe = pipeline(task=\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=1024, device=device_id) local_llm = HuggingFacePipeline(pipeline=pipe) ``` <CodeOutputBlock lang=\"python\"> ``` Loading checkpoint shards: 100%|██████████| 8/8 [00:32<00:00, 4.11s/it] ``` </CodeOutputBlock> ```python from langchain_community.utilities import SQLDatabase from langchain_experimental.sql import SQLDatabaseChain db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\", include_tables=['Customer']) local_chain = SQLDatabaseChain.from_llm(local_llm, db, verbose=True, return_intermediate_steps=True, use_query_checker=True) ``` This model should work for very simple SQL queries, as long as you use the query checker as specified above, e.g.: ```python local_chain(\"How many customers are there?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many customers are there? SQLQuery: /workspace/langchain/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset warnings.warn( /workspace/langchain/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset warnings.warn( SELECT count(*) FROM Customer SQLResult: [(59,)] Answer: /workspace/langchain/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset warnings.warn( [59] > Finished chain. {'query': 'How many customers are there?', 'result': '[59]', 'intermediate_steps': [{'input': 'How many customers are there?\\nSQLQuery:SELECT count(*) FROM Customer\\nSQLResult: [(59,)]\\nAnswer:', 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLuís\\tGonçalves\\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tSão José dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tKöhler\\tNone\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFrançois\\tTremblay\\tNone\\t1498 rue Bélanger\\tMontréal\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/', 'stop': ['\\nSQLResult:']}, 'SELECT count(*) FROM Customer', {'query': 'SELECT count(*) FROM Customer', 'dialect': 'sqlite'}, 'SELECT count(*) FROM Customer', '[(59,)]']} ``` </CodeOutputBlock> Even this relatively large model will most likely fail to generate more complicated SQL by itself. However, you can log its inputs and outputs so that you can hand-correct them and use the corrected examples for few-shot prompt examples later. In practice, you could log any executions of your chain that raise exceptions (as shown in the example below) or get direct user feedback in cases where the results are incorrect (but did not raise an exception). ```bash poetry run pip install pyyaml langchain_chroma import yaml ``` <CodeOutputBlock lang=\"bash\"> ``` huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks... To disable this warning, you can either: - Avoid using `tokenizers` before the fork if possible - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false) 11842.36s - pydevd: Sending message related to process being replaced timed-out after 5 seconds Requirement already satisfied: pyyaml in /workspace/langchain/.venv/lib/python3.9/site-packages (6.0) Requirement already satisfied: chromadb in /workspace/langchain/.venv/lib/python3.9/site-packages (0.3.21) Requirement already satisfied: pandas>=1.3 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (2.0.1) Requirement already satisfied: requests>=2.28 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (2.28.2) Requirement already satisfied: pydantic>=1.9 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (1.10.7) Requirement already satisfied: hnswlib>=0.7 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.7.0) Requirement already satisfied: clickhouse-connect>=0.5.7 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.5.20) Requirement already satisfied: sentence-transformers>=2.2.2 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (2.2.2) Requirement already satisfied: duckdb>=0.7.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.7.1) Requirement already satisfied: fastapi>=0.85.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.95.1) Requirement already satisfied: uvicorn[standard]>=0.18.3 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (0.21.1) Requirement already satisfied: numpy>=1.21.6 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (1.24.3) Requirement already satisfied: posthog>=2.4.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from chromadb) (3.0.1) Requirement already satisfied: certifi in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7) Requirement already satisfied: urllib3>=1.26 in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15) Requirement already satisfied: pytz in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3) Requirement already satisfied: zstandard in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0) Requirement already satisfied: lz4 in /workspace/langchain/.venv/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2) Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from fastapi>=0.85.1->chromadb) (0.26.1) Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/langchain/.venv/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2.8.2) Requirement already satisfied: tzdata>=2022.1 in /workspace/langchain/.venv/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2023.3) Requirement already satisfied: six>=1.5 in /workspace/langchain/.venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.16.0) Requirement already satisfied: monotonic>=1.5 in /workspace/langchain/.venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6) Requirement already satisfied: backoff>=1.10.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1) Requirement already satisfied: typing-extensions>=4.2.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (4.5.0) Requirement already satisfied: charset-normalizer<4,>=2 in /workspace/langchain/.venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.1.0) Requirement already satisfied: idna<4,>=2.5 in /workspace/langchain/.venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.4) Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.28.1) Requirement already satisfied: tqdm in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0) Requirement already satisfied: torch>=1.6.0 in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.13.1) Requirement already satisfied: torchvision in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1) Requirement already satisfied: scikit-learn in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2) Requirement already satisfied: scipy in /workspace/langchain/.venv/lib/python3.9/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.9.3)",
      "<6-hop>\n\nAdding Memory How to add memory to a SQLDatabaseChain: ```python from langchain_openai import OpenAI from langchain_community.utilities import SQLDatabase from langchain_experimental.sql import SQLDatabaseChain ``` Set up the SQLDatabase and LLM ```python db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\") llm = OpenAI(temperature=0, verbose=True) ``` Set up the memory ```python from langchain.memory import ConversationBufferMemory memory = ConversationBufferMemory() ``` Now we need to add a place for memory in the prompt template ```python from langchain.prompts import PromptTemplate PROMPT_SUFFIX = \"\"\"Only use the following tables: {table_info} Previous Conversation: {history} Question: {input}\"\"\" _DEFAULT_TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Unless the user specifies in his question a specific number of examples he wishes to obtain, always limit your query to at most {top_k} results. You can order the results by a relevant column to return the most interesting examples in the database. Never query for all the columns from a specific table, only ask for a few relevant columns given the question. Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table. Use the following format: Question: Question here SQLQuery: SQL Query to run SQLResult: Result of the SQLQuery Answer: Final answer here \"\"\" PROMPT = PromptTemplate.from_template( _DEFAULT_TEMPLATE + PROMPT_SUFFIX, ) ``` Now let's create and run out chain ```python db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=PROMPT, verbose=True, memory=memory) db_chain.run(\"name one employee\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... name one employee SQLQuery:SELECT FirstName, LastName FROM Employee LIMIT 1 SQLResult: [('Andrew', 'Adams')] Answer:Andrew Adams > Finished chain. 'Andrew Adams' ``` </CodeOutputBlock> ```python db_chain.run(\"how many letters in their name?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... how many letters in their name? SQLQuery:SELECT LENGTH(FirstName) + LENGTH(LastName) AS 'NameLength' FROM Employee WHERE FirstName = 'Andrew' AND LastName = 'Adams' SQLResult: [(11,)] Answer:Andrew Adams has 11 letters in their name. > Finished chain. 'Andrew Adams has 11 letters in their name.' ``` </CodeOutputBlock> ## table: GenreId Name 1 Rock 2 Jazz 3 Metal */ sql_cmd: SELECT \"Name\" FROM \"Genre\" WHERE \"Name\" LIKE 'r%'; sql_result: \"[('Rock',), ('Rock and Roll',), ('Reggae',), ('R&B/Soul',)]\" answer: The genres that start with 'r' are Rock, Rock and Roll, Reggae and R&B/Soul. \"\"\" ``` Now that you have some examples (with manually corrected output SQL), you can do few-shot prompt seeding the usual way: ```python from langchain.prompts import FewShotPromptTemplate, PromptTemplate from langchain.chains.sql_database.prompt import _sqlite_prompt, PROMPT_SUFFIX from langchain_huggingface import HuggingFaceEmbeddings from langchain.prompts.example_selector.semantic_similarity import SemanticSimilarityExampleSelector from langchain_chroma import Chroma example_prompt = PromptTemplate( input_variables=[\"table_info\", \"input\", \"sql_cmd\", \"sql_result\", \"answer\"], template=\"{table_info}\\n\\nQuestion: {input}\\nSQLQuery: {sql_cmd}\\nSQLResult: {sql_result}\\nAnswer: {answer}\", ) examples_dict = yaml.safe_load(YAML_EXAMPLES) local_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\") example_selector = SemanticSimilarityExampleSelector.from_examples( # This is the list of examples available to select from. examples_dict, # This is the embedding class used to produce embeddings which are used to measure semantic similarity. local_embeddings, # This is the VectorStore class that is used to store the embeddings and do a similarity search over. Chroma, # type: ignore # This is the number of examples to produce and include per prompt k=min(3, len(examples_dict)), ) few_shot_prompt = FewShotPromptTemplate( example_selector=example_selector, example_prompt=example_prompt, prefix=_sqlite_prompt + \"Here are some examples:\", suffix=PROMPT_SUFFIX, input_variables=[\"table_info\", \"input\", \"top_k\"], ) ``` <CodeOutputBlock lang=\"python\"> ``` Using embedded DuckDB without persistence: data will be transient ``` </CodeOutputBlock> The model should do better now with this few-shot prompt, especially for inputs similar to the examples you have seeded it with. ```python local_chain = SQLDatabaseChain.from_llm(local_llm, db, prompt=few_shot_prompt, use_query_checker=True, verbose=True, return_intermediate_steps=True) ``` ```python result = local_chain(\"How many customers are from Brazil?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many customers are from Brazil? SQLQuery:SELECT count(*) FROM Customer WHERE Country = \"Brazil\"; SQLResult: [(5,)] Answer:[5] > Finished chain. ``` </CodeOutputBlock> ```python result = local_chain(\"How many customers are not from Brazil?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many customers are not from Brazil? SQLQuery:SELECT count(*) FROM customer WHERE country NOT IN (SELECT country FROM customer WHERE country = 'Brazil') SQLResult: [(54,)] Answer:54 customers are not from Brazil. > Finished chain. ``` </CodeOutputBlock> ```python result = local_chain(\"How many customers are there in total?\") ``` <CodeOutputBlock lang=\"python\"> ``` > Entering new SQLDatabaseChain chain... How many customers are there in total? SQLQuery:SELECT count(*) FROM Customer; SQLResult: [(59,)] Answer:There are 59 customers in total. > Finished chain. ``` </CodeOutputBlock>",
      "<7-hop>\n\nAsync Operations Vector stores are usually run as a separate service that requires some IO operations, and therefore they might be called asynchronously. That gives performance benefits as you don't waste time waiting for responses from external services. That might also be important if you work with an asynchronous framework, such as [FastAPI](https://fastapi.tiangolo.com/). LangChain supports async operation on vector stores. All the methods might be called using their async counterparts, with the prefix `a`, meaning `async`. ```python docs = await db.asimilarity_search(query) docs ``` ```output [Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.', metadata={'source': 'state_of_the_union.txt'}), Document(page_content='A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling. \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers. \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.', metadata={'source': 'state_of_the_union.txt'}), Document(page_content='And for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \\n\\nAnd soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \\n\\nSo tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together. \\n\\nFirst, beat the opioid epidemic.', metadata={'source': 'state_of_the_union.txt'}), Document(page_content='Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \\n\\nAnd as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up. \\n\\nThat ends on my watch. \\n\\nMedicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \\n\\nWe’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \\n\\nLet’s pass the Paycheck Fairness Act and paid leave. \\n\\nRaise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \\n\\nLet’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges.', metadata={'source': 'state_of_the_union.txt'})] ```"
    ],
    "ground_truth": "The SQLDatabaseChain can be utilized for async operations by using its async counterparts for methods, which allows for non-blocking calls to external services. This is particularly beneficial in asynchronous frameworks like FastAPI. For example, you can perform a similarity search using the async method by calling `await db.asimilarity_search(query)`. This approach ensures that the application does not waste time waiting for responses, thus improving performance and responsiveness when handling SQL queries and their results.",
    "synthesizer_name": "multi_hop_abstract_query_synthesizer"
  },
  {
    "question": "What are the capabilities of Microsoft Word and how does it integrate with Microsoft Azure services for document processing?",
    "contexts": [
      "<1-hop>\n\nDocument loaders ### Azure AI Data >[Azure AI Studio](https://ai.azure.com/) provides the capability to upload data assets > to cloud storage and register existing data assets from the following sources: > >- `Microsoft OneLake` >- `Azure Blob Storage` >- `Azure Data Lake gen 2` First, you need to install several python packages. ```bash pip install azureml-fsspec, azure-ai-generative ``` See a [usage example](/docs/integrations/document_loaders/azure_ai_data). ```python from langchain.document_loaders import AzureAIDataLoader ``` ### Azure AI Document Intelligence >[Azure AI Document Intelligence](https://aka.ms/doc-intelligence) (formerly known > as `Azure Form Recognizer`) is machine-learning > based service that extracts texts (including handwriting), tables, document structures, > and key-value-pairs > from digital or scanned PDFs, images, Office and HTML files. > > Document Intelligence supports `PDF`, `JPEG/JPG`, `PNG`, `BMP`, `TIFF`, `HEIF`, `DOCX`, `XLSX`, `PPTX` and `HTML`. First, you need to install a python package. ```bash pip install azure-ai-documentintelligence ``` See a [usage example](/docs/integrations/document_loaders/azure_document_intelligence). ```python from langchain.document_loaders import AzureAIDocumentIntelligenceLoader ``` ### Azure Blob Storage >[Azure Blob Storage](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction) is Microsoft's object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn't adhere to a particular data model or definition, such as text or binary data. >[Azure Files](https://learn.microsoft.com/en-us/azure/storage/files/storage-files-introduction) offers fully managed > file shares in the cloud that are accessible via the industry standard Server Message Block (`SMB`) protocol, > Network File System (`NFS`) protocol, and `Azure Files REST API`. `Azure Files` are based on the `Azure Blob Storage`. `Azure Blob Storage` is designed for: - Serving images or documents directly to a browser. - Storing files for distributed access. - Streaming video and audio. - Writing to log files. - Storing data for backup and restore, disaster recovery, and archiving. - Storing data for analysis by an on-premises or Azure-hosted service. ```bash pip install azure-storage-blob ``` See a [usage example for the Azure Blob Storage](/docs/integrations/document_loaders/azure_blob_storage_container). ```python from langchain_community.document_loaders import AzureBlobStorageContainerLoader ``` See a [usage example for the Azure Files](/docs/integrations/document_loaders/azure_blob_storage_file). ```python from langchain_community.document_loaders import AzureBlobStorageFileLoader ``` ### Microsoft OneDrive >[Microsoft OneDrive](https://en.wikipedia.org/wiki/OneDrive) (formerly `SkyDrive`) is a file-hosting service operated by Microsoft. First, you need to install a python package. ```bash pip install o365 ``` See a [usage example](/docs/integrations/document_loaders/microsoft_onedrive). ```python from langchain_community.document_loaders import OneDriveLoader ``` ### Microsoft OneDrive File >[Microsoft OneDrive](https://en.wikipedia.org/wiki/OneDrive) (formerly `SkyDrive`) is a file-hosting service operated by Microsoft. First, you need to install a python package. ```bash pip install o365 ``` ```python from langchain_community.document_loaders import OneDriveFileLoader ``` ### Microsoft Word >[Microsoft Word](https://www.microsoft.com/en-us/microsoft-365/word) is a word processor developed by Microsoft. See a [usage example](/docs/integrations/document_loaders/microsoft_word). ```python from langchain_community.document_loaders import UnstructuredWordDocumentLoader ``` ### Microsoft Excel >[Microsoft Excel](https://en.wikipedia.org/wiki/Microsoft_Excel) is a spreadsheet editor developed by > Microsoft for Windows, macOS, Android, iOS and iPadOS. > It features calculation or computation capabilities, graphing tools, pivot tables, and a macro programming > language called Visual Basic for Applications (VBA). Excel forms part of the Microsoft 365 suite of software. The `UnstructuredExcelLoader` is used to load `Microsoft Excel` files. The loader works with both `.xlsx` and `.xls` files. The page content will be the raw text of the Excel file. If you use the loader in `\"elements\"` mode, an HTML representation of the Excel file will be available in the document metadata under the `text_as_html` key. See a [usage example](/docs/integrations/document_loaders/microsoft_excel). ```python from langchain_community.document_loaders import UnstructuredExcelLoader ``` ### Microsoft SharePoint >[Microsoft SharePoint](https://en.wikipedia.org/wiki/SharePoint) is a website-based collaboration system > that uses workflow applications, “list” databases, and other web parts and security features to > empower business teams to work together developed by Microsoft. See a [usage example](/docs/integrations/document_loaders/microsoft_sharepoint). ```python from langchain_community.document_loaders.sharepoint import SharePointLoader ``` ### Microsoft PowerPoint >[Microsoft PowerPoint](https://en.wikipedia.org/wiki/Microsoft_PowerPoint) is a presentation program by Microsoft. See a [usage example](/docs/integrations/document_loaders/microsoft_powerpoint). ```python from langchain_community.document_loaders import UnstructuredPowerPointLoader ``` ### Microsoft OneNote First, let's install dependencies: ```bash pip install bs4 msal ``` See a [usage example](/docs/integrations/document_loaders/microsoft_onenote). ```python from langchain_community.document_loaders.onenote import OneNoteLoader ``` ### Playwright URL Loader >[Playwright](https://github.com/microsoft/playwright) is an open-source automation tool > developed by `Microsoft` that allows you to programmatically control and automate > web browsers. It is designed for end-to-end testing, scraping, and automating > tasks across various web browsers such as `Chromium`, `Firefox`, and `WebKit`. First, let's install dependencies: ```bash pip install playwright unstructured ``` See a [usage example](/docs/integrations/document_loaders/url/#playwright-url-loader). ```python from langchain_community.document_loaders.onenote import OneNoteLoader ``` ##",
      "<2-hop>\n\n# Chat models ## Overview Large Language Models (LLMs) are advanced machine learning models that excel in a wide range of language-related tasks such as text generation, translation, summarization, question answering, and more, without needing task-specific fine tuning for every scenario. Modern LLMs are typically accessed through a chat model interface that takes a list of [messages](/docs/concepts/messages) as input and returns a [message](/docs/concepts/messages) as output. The newest generation of chat models offer additional capabilities: * [Tool calling](/docs/concepts/tool_calling): Many popular chat models offer a native [tool calling](/docs/concepts/tool_calling) API. This API allows developers to build rich applications that enable LLMs to interact with external services, APIs, and databases. Tool calling can also be used to extract structured information from unstructured data and perform various other tasks. * [Structured output](/docs/concepts/structured_outputs): A technique to make a chat model respond in a structured format, such as JSON that matches a given schema. * [Multimodality](/docs/concepts/multimodality): The ability to work with data other than text; for example, images, audio, and video. ## Features LangChain provides a consistent interface for working with chat models from different providers while offering additional features for monitoring, debugging, and optimizing the performance of applications that use LLMs. * Integrations with many chat model providers (e.g., Anthropic, OpenAI, Ollama, Microsoft Azure, Google Vertex, Amazon Bedrock, Hugging Face, Cohere, Groq). Please see [chat model integrations](/docs/integrations/chat/) for an up-to-date list of supported models. * Use either LangChain's [messages](/docs/concepts/messages) format or OpenAI format. * Standard [tool calling API](/docs/concepts/tool_calling): standard interface for binding tools to models, accessing tool call requests made by models, and sending tool results back to the model. * Standard API for [structuring outputs](/docs/concepts/structured_outputs/#structured-output-method) via the `with_structured_output` method. * Provides support for [async programming](/docs/concepts/async), [efficient batching](/docs/concepts/runnables/#optimized-parallel-execution-batch), [a rich streaming API](/docs/concepts/streaming). * Integration with [LangSmith](https://docs.smith.langchain.com) for monitoring and debugging production-grade applications based on LLMs. * Additional features like standardized [token usage](/docs/concepts/messages/#aimessage), [rate limiting](#rate-limiting), [caching](#caching) and more. ## Integrations LangChain has many chat model integrations that allow you to use a wide variety of models from different providers. These integrations are one of two types: 1. **Official models**: These are models that are officially supported by LangChain and/or model provider. You can find these models in the `langchain-<provider>` packages. 2. **Community models**: There are models that are mostly contributed and supported by the community. You can find these models in the `langchain-community` package. LangChain chat models are named with a convention that prefixes \"Chat\" to their class names (e.g., `ChatOllama`, `ChatAnthropic`, `ChatOpenAI`, etc.). Please review the [chat model integrations](/docs/integrations/chat/) for a list of supported models. :::note Models that do **not** include the prefix \"Chat\" in their name or include \"LLM\" as a suffix in their name typically refer to older models that do not follow the chat model interface and instead use an interface that takes a string as input and returns a string as output. ::: ## "
    ],
    "ground_truth": "Microsoft Word is a word processor developed by Microsoft that allows users to create and edit text documents. It supports various file formats and provides features for formatting, editing, and collaborating on documents. In terms of integration with Microsoft Azure services, Microsoft Word can be utilized alongside Azure AI Document Intelligence, which is a machine-learning service that extracts text, tables, and document structures from various file types, including Office files like DOCX. This integration enables users to leverage Azure's capabilities for enhanced document processing and analysis.",
    "synthesizer_name": "multi_hop_specific_query_synthesizer"
  },
  {
    "question": "What are the key changes introduced in LangChain v0.3 regarding optional dependencies and the transition from langchain-community to langchain-x?",
    "contexts": [
      "<1-hop>\n\nFormatting and Linting Run these locally before submitting a PR; the CI system will check also. ### Code Formatting Formatting for this project is done via [ruff](https://docs.astral.sh/ruff/rules/). To run formatting for docs, cookbook and templates: ```bash make format ``` To run formatting for a library, run the same command from the relevant library directory: ```bash cd libs/{LIBRARY} make format ``` Additionally, you can run the formatter only on the files that have been modified in your current branch as compared to the master branch using the format_diff command: ```bash make format_diff ``` This is especially useful when you have made changes to a subset of the project and want to ensure your changes are properly formatted without affecting the rest of the codebase. #### Linting Linting for this project is done via a combination of [ruff](https://docs.astral.sh/ruff/rules/) and [mypy](http://mypy-lang.org/). To run linting for docs, cookbook and templates: ```bash make lint ``` To run linting for a library, run the same command from the relevant library directory: ```bash cd libs/{LIBRARY} make lint ``` In addition, you can run the linter only on the files that have been modified in your current branch as compared to the master branch using the lint_diff command: ```bash make lint_diff ``` This can be very helpful when you've made changes to only certain parts of the project and want to ensure your changes meet the linting standards without having to check the entire codebase. We recognize linting can be annoying - if you do not want to do it, please contact a project maintainer, and they can help you with it. We do not want this to be a blocker for good code getting contributed. ### Spellcheck Spellchecking for this project is done via [codespell](https://github.com/codespell-project/codespell). Note that `codespell` finds common typos, so it could have false-positive (correctly spelled but rarely used) and false-negatives (not finding misspelled) words. To check spelling for this project: ```bash make spell_check ``` To fix spelling in place: ```bash make spell_fix ``` If codespell is incorrectly flagging a word, you can skip spellcheck for that word by adding it to the codespell config in the `pyproject.toml` file. ```python [tool.codespell] ... # Add here: ignore-words-list = 'momento,collison,ned,foor,reworkd,parth,whats,aapply,mysogyny,unsecure' ``` ## Working with Optional Dependencies `langchain`, `langchain-community`, and `langchain-experimental` rely on optional dependencies to keep these packages lightweight. `langchain-core` and partner packages **do not use** optional dependencies in this way. You'll notice that `pyproject.toml` and `uv.lock` are **not** touched when you add optional dependencies below. If you're adding a new dependency to Langchain, assume that it will be an optional dependency, and that most users won't have it installed. Users who do not have the dependency installed should be able to **import** your code without any side effects (no warnings, no errors, no exceptions). To introduce the dependency to a library, please do the following: 1. Open extended_testing_deps.txt and add the dependency 2. Add a unit test that the very least attempts to import the new code. Ideally, the unit test makes use of lightweight fixtures to test the logic of the code. 3. Please use the `@pytest.mark.requires(package_name)` decorator for any unit tests that require the dependency. ## Adding a Jupyter Notebook If you are adding a Jupyter Notebook example, you'll want to run with `test` dependencies: ```bash uv run --group test jupyter notebook ``` When you run `uv sync`, the `langchain` package is installed as editable in the virtualenv, so your new logic can be imported into the notebook.",
      "<2-hop>\n\n# LangChain v0.3 *Last updated: 09.16.24* ## What's changed * All packages have been upgraded from Pydantic 1 to Pydantic 2 internally. Use of Pydantic 2 in user code is fully supported with all packages without the need for bridges like `langchain_core.pydantic_v1` or `pydantic.v1`. * Pydantic 1 will no longer be supported as it reached its end-of-life in June 2024. * Python 3.8 will no longer be supported as its end-of-life is October 2024. **These are the only breaking changes.** ## What’s new The following features have been added during the development of 0.2.x: - Moved more integrations from `langchain-community` to their own `langchain-x` packages. This is a non-breaking change, as the legacy implementations are left in `langchain-community` and marked as deprecated. This allows us to better manage the dependencies of, test, and version these integrations. You can see all the latest integration packages in the [API reference](https://python.langchain.com/v0.2/api_reference/reference.html#integrations). - Simplified tool definition and usage. Read more [here](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/). - Added utilities for interacting with chat models: [universal model constructor](https://python.langchain.com/v0.2/docs/how_to/chat_models_universal_init/), [rate limiter](https://python.langchain.com/v0.2/docs/how_to/chat_model_rate_limiting/), [message utilities](https://python.langchain.com/v0.2/docs/how_to/#messages), - Added the ability to [dispatch custom events](https://python.langchain.com/v0.2/docs/how_to/callbacks_custom_events/). - Revamped integration docs and API reference. Read more [here](https://blog.langchain.dev/langchain-integration-docs-revamped/). - Marked as deprecated a number of legacy chains and added migration guides for all of them. These are slated for removal in `langchain` 1.0.0. See the deprecated chains and associated [migration guides here](https://python.langchain.com/v0.2/docs/versions/migrating_chains/). ##"
    ],
    "ground_truth": "In LangChain v0.3, a significant change is the movement of more integrations from `langchain-community` to their own `langchain-x` packages. This transition is non-breaking as the legacy implementations remain in `langchain-community` but are marked as deprecated. Additionally, the project emphasizes that `langchain`, `langchain-community`, and `langchain-experimental` rely on optional dependencies to maintain a lightweight structure, allowing users without these dependencies to import code without side effects. This approach ensures that the packages remain accessible and functional for users who may not have all optional dependencies installed.",
    "synthesizer_name": "multi_hop_specific_query_synthesizer"
  }
]